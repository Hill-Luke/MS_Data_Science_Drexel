{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module submission header\n",
    "### Submission preparation instructions \n",
    "_Completion of this header is mandatory, subject to a 2-point deduction to the assignment._ Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. You must fill out all group member Names and Drexel email addresses in the below markdown list, under header __Module submission group__. It is required to fill out descriptive notes pertaining to any tutoring support received in the completion of this submission under the __Additional submission comments__ section at the bottom of the header. If no tutoring support was received, leave NA in place. You may as well list other optional comments pertaining to the submission at bottom. _Any distruption of this header's formatting will make your group liable to the 2-point deduction._\n",
    "\n",
    "### Module submission group\n",
    "- Group member 1\n",
    "    - Name: Luke Hill\n",
    "    - Email: lh967@drexel.edu\n",
    "\n",
    "\n",
    "### Additional submission comments\n",
    "- Tutoring support received: NA\n",
    "- Other (other): NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Group 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module D _(20 points)_\n",
    "\n",
    "For this assignment, we'll be working with a previously-accessed subset of the [Lending Club Loan Dataset](https://www.kaggle.com/wordsforthewise/lending-club) located via the local path `'./data/loan_extra-small.csv'`.\n",
    "\n",
    "__D1.__ _(3 points)_  First, complete the function to read the csv and note the first line contains the header. Separately a return the `header` (a list of strings) and `loan_data` (a list of list) as a pair for the function's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1:Function(3/3)\n",
    "\n",
    "import csv\n",
    "\n",
    "def read_loans(file_path):\n",
    "    loan_reader = csv.reader(open(file_path, \"r\"))\n",
    "    loan_data=[]\n",
    "    header = next(loan_reader)\n",
    "    for row in loan_reader:\n",
    "        loan_data.append(row)\n",
    "    return header, loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "loan status:  Current\n",
    "\n",
    "[('id', ''),\n",
    " ('member_id', ''),\n",
    " ('loan_amnt', '2500'),\n",
    " ('funded_amnt', '2500'),\n",
    " ('funded_amnt_inv', '2500'),\n",
    " ('term', '36 months'),\n",
    " ('int_rate', '13.56'),\n",
    " ('installment', '84.92'),\n",
    " ('grade', 'C'),\n",
    " ('sub_grade', 'C1'),\n",
    " ('emp_title', 'Chef'),\n",
    " ('emp_length', '10+ years'),\n",
    " ('home_ownership', 'RENT'),\n",
    " ('annual_inc', '55000'),\n",
    " ('verification_status', 'Not Verified'),\n",
    " ('issue_d', 'Dec-2018'),\n",
    " ('loan_status', 'Current'),\n",
    " ('pymnt_plan', 'n'),\n",
    " ('url', ''),\n",
    " ('desc', ''),\n",
    " ('purpose', 'debt_consolidation'),\n",
    " ('title', 'Debt consolidation'),\n",
    " ('zip_code', '109xx'),\n",
    " ('addr_state', 'NY'),\n",
    " ('dti', '18.24')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan status:  Current\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('id', ''),\n",
       " ('member_id', ''),\n",
       " ('loan_amnt', '2500'),\n",
       " ('funded_amnt', '2500'),\n",
       " ('funded_amnt_inv', '2500'),\n",
       " ('term', '36 months'),\n",
       " ('int_rate', '13.56'),\n",
       " ('installment', '84.92'),\n",
       " ('grade', 'C'),\n",
       " ('sub_grade', 'C1'),\n",
       " ('emp_title', 'Chef'),\n",
       " ('emp_length', '10+ years'),\n",
       " ('home_ownership', 'RENT'),\n",
       " ('annual_inc', '55000'),\n",
       " ('verification_status', 'Not Verified'),\n",
       " ('issue_d', 'Dec-2018'),\n",
       " ('loan_status', 'Current'),\n",
       " ('pymnt_plan', 'n'),\n",
       " ('url', ''),\n",
       " ('desc', ''),\n",
       " ('purpose', 'debt_consolidation'),\n",
       " ('title', 'Debt consolidation'),\n",
       " ('zip_code', '109xx'),\n",
       " ('addr_state', 'NY'),\n",
       " ('dti', '18.24')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D1:SanityCheck\n",
    "\n",
    "header, loan_data = read_loans('./data/loan_extra-small.csv')\n",
    "\n",
    "print(\"loan status: \", loan_data[0][header.index(\"loan_status\")])\n",
    "list(zip(header,loan_data[0]))[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D2.__ _(4 points)_ Now complete the function below to create a dictionary named `statuses` whose keys are the entries in the `loan_status` and values are boolean values, describing `1`- or `0`-loans, where loans that have `\"Current\"`, `\"Fully Paid\"`, or `\"Issued\"` in the `loan_status` field are `1`-loans, and all others are `0`-loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D2:Function(4/4)\n",
    "\n",
    "import re \n",
    "\n",
    "def categorize_satuses(loan_data, header):\n",
    "    statuses = {}\n",
    "\n",
    "    # Define the regular expressions for 1-loans and 0-loans\n",
    "    one_loan_regex = re.compile(r'^(Current|Fully Paid|Issued)$')\n",
    "    \n",
    "    # Extract the 'loan_status' column index\n",
    "    loan_status_index = header.index('loan_status')\n",
    "    \n",
    "    # Iterate through 'loan_data' and categorize the loans\n",
    "    for row in loan_data:\n",
    "        loan_status = row[loan_status_index]\n",
    "        is_one_loan = bool(one_loan_regex.match(loan_status))\n",
    "        statuses[loan_status] = int(is_one_loan)\n",
    "    \n",
    "    return statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "{'Current': 1,\n",
    " 'Fully Paid': 1,\n",
    " 'Charged Off': 0,\n",
    " 'Late (16-30 days)': 0,\n",
    " 'Late (31-120 days)': 0}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Current': 1,\n",
       " 'Fully Paid': 1,\n",
       " 'Charged Off': 0,\n",
       " 'Late (16-30 days)': 0,\n",
       " 'Late (31-120 days)': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D2:SanityCheck\n",
    "\n",
    "statuses = categorize_satuses(loan_data, header)\n",
    "statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D3.__ _(8 pts)_ The `desc` field contains text descriptions of loans. Complete the function to tokenize each loan description and count the words for `1`- and `0`-loan descriptions, putting counts into two separate `Counter()` data structures according to each loan's status in `statuses`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D3:Function(6/8)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def count_desc_words(loan_data, header):\n",
    "    counts = defaultdict(Counter)\n",
    "    loan_status_index = header.index('loan_status')\n",
    "    desc_index = header.index('desc')\n",
    "    one_loan_regex = re.compile(r'^(Current|Fully Paid|Issued)$')\n",
    "    # Iterate through the loan data\n",
    "    for row in loan_data:\n",
    "        loan_status = row[loan_status_index]\n",
    "        loan_desc = row[desc_index]\n",
    "\n",
    "        # Tokenize the loan description\n",
    "        words = word_tokenize(loan_desc)\n",
    "\n",
    "        # Determine the status using the label mapping\n",
    "        is_one_loan = bool(one_loan_regex.match(loan_status))\n",
    "        counts[is_one_loan].update(words)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "The top 25 'good/bad'-loan words are: \n",
    "1  (good, bad):  ('>', 102166) ('>', 18838)\n",
    "2  (good, bad):  ('on', 55911) ('<', 10153)\n",
    "3  (good, bad):  ('<', 54586) ('br', 10153)\n",
    "4  (good, bad):  ('br', 54585) ('on', 10089)\n",
    "5  (good, bad):  ('to', 50785) ('to', 8819)\n",
    "6  (good, bad):  ('added', 47661) ('added', 8702)\n",
    "7  (good, bad):  ('Borrower', 47584) ('Borrower', 8685)\n",
    "8  (good, bad):  ('I', 39943) ('I', 6778)\n",
    "9  (good, bad):  ('and', 31902) ('and', 5873)\n",
    "10  (good, bad):  ('.', 30952) ('my', 5176)\n",
    "11  (good, bad):  ('credit', 28660) ('.', 4902)\n",
    "12  (good, bad):  ('my', 27339) ('credit', 4844)\n",
    "13  (good, bad):  ('a', 25077) ('a', 3856)\n",
    "14  (good, bad):  ('the', 19275) ('pay', 3538)\n",
    "15  (good, bad):  ('pay', 19037) ('off', 3274)\n",
    "16  (good, bad):  ('off', 18624) ('loan', 2992)\n",
    "17  (good, bad):  ('loan', 18028) ('the', 2860)\n",
    "18  (good, bad):  ('debt', 17377) ('debt', 2801)\n",
    "19  (good, bad):  (',', 16079) (',', 2636)\n",
    "20  (good, bad):  ('of', 14980) ('of', 2613)\n",
    "21  (good, bad):  ('cards', 14459) ('cards', 2593)\n",
    "22  (good, bad):  ('for', 13588) ('for', 2340)\n",
    "23  (good, bad):  ('have', 13222) ('have', 2330)\n",
    "24  (good, bad):  ('interest', 12357) ('card', 1861)\n",
    "25  (good, bad):  ('card', 12345) ('consolidate', 1722)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lukeh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 25 'good/bad'-loan words are: \n",
      "1  (good, bad):  ('>', 102166) ('>', 18838)\n",
      "2  (good, bad):  ('on', 55911) ('<', 10153)\n",
      "3  (good, bad):  ('<', 54586) ('br', 10153)\n",
      "4  (good, bad):  ('br', 54585) ('on', 10089)\n",
      "5  (good, bad):  ('to', 50785) ('to', 8819)\n",
      "6  (good, bad):  ('added', 47661) ('added', 8702)\n",
      "7  (good, bad):  ('Borrower', 47584) ('Borrower', 8685)\n",
      "8  (good, bad):  ('I', 39943) ('I', 6778)\n",
      "9  (good, bad):  ('and', 31902) ('and', 5873)\n",
      "10  (good, bad):  ('.', 30952) ('my', 5176)\n",
      "11  (good, bad):  ('credit', 28660) ('.', 4902)\n",
      "12  (good, bad):  ('my', 27339) ('credit', 4844)\n",
      "13  (good, bad):  ('a', 25077) ('a', 3856)\n",
      "14  (good, bad):  ('the', 19275) ('pay', 3538)\n",
      "15  (good, bad):  ('pay', 19037) ('off', 3274)\n",
      "16  (good, bad):  ('off', 18624) ('loan', 2992)\n",
      "17  (good, bad):  ('loan', 18028) ('the', 2860)\n",
      "18  (good, bad):  ('debt', 17377) ('debt', 2801)\n",
      "19  (good, bad):  (',', 16079) (',', 2636)\n",
      "20  (good, bad):  ('of', 14980) ('of', 2613)\n",
      "21  (good, bad):  ('cards', 14459) ('cards', 2593)\n",
      "22  (good, bad):  ('for', 13588) ('for', 2340)\n",
      "23  (good, bad):  ('have', 13222) ('have', 2330)\n",
      "24  (good, bad):  ('interest', 12357) ('card', 1861)\n",
      "25  (good, bad):  ('card', 12345) ('consolidate', 1722)\n"
     ]
    }
   ],
   "source": [
    "# D3:SanityCheck\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "counts = count_desc_words(loan_data, header)\n",
    "print('The top 25 \\'good/bad\\'-loan words are: ')\n",
    "for good_word, bad_word, i in zip(counts[1].most_common(25), \n",
    "                                  counts[0].most_common(25),\n",
    "                                  range(25)):\n",
    "    print(i+1,\" (good, bad): \", \n",
    "          good_word, bad_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the output most common words for `1`- and `0`-loans, determine if there an apparent difference in the words used and respond to the `Inline(2/8)` question, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same\n"
     ]
    }
   ],
   "source": [
    "# D3:Inline(2/8)\n",
    "\n",
    "# Just looking at the top 25 words for each category, \n",
    "# are more words the same than different?\n",
    "# print either \"Same\" or \"Different\"\n",
    "print(\"Same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D4.__ _(5 points)_ Considering the lack of discernability between the `top_n` (a function parameter) word lists for each cateory, you must now complete the function, which is an exercise in sets, determining which words each category _exclusively_ uses.\n",
    "\n",
    "In particular, you must remove the `0`-loan set's words from the `1`-loan's set, and vice versa, storing these respectively in the `good_notin_bad` and `bad_notin_good` sets, respectively. If the data are meaningful (an integrity check), one might expect more-positive words in the `good_notin_bad`, and more-negative words in the `bad_notin_good` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D4:Function(4/5)\n",
    "\n",
    "def get_set_differences(counts, top_n):\n",
    "    good_notin_bad, bad_notin_good = set(), set()\n",
    "    \n",
    "    # Extract the top words from '1' (good loans) and '0' (bad loans) categories\n",
    "    top_good_words = {word for word, _ in counts[1].most_common(top_n)}\n",
    "    top_bad_words = {word for word, _ in counts[0].most_common(top_n)}\n",
    "    \n",
    "    # Calculate words exclusive to each category\n",
    "    good_notin_bad = top_good_words - top_bad_words\n",
    "    bad_notin_good = top_bad_words - top_good_words\n",
    "    \n",
    "    return good_notin_bad, bad_notin_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "({'!', 'it', 'lower', 'rate'}, {'bills', 'consolidation', 'help', 'need'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'!', 'it', 'lower', 'rate'}, {'bills', 'consolidation', 'help', 'need'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D4:SanityCheck\n",
    "\n",
    "good_notin_bad, bad_notin_good = get_set_differences(counts, 50)\n",
    "good_notin_bad, bad_notin_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meaningful\n"
     ]
    }
   ],
   "source": [
    "# D4:Inline(1/5)\n",
    "\n",
    "# Now that we can see the separately-used words, do they appear\n",
    "# meaningfully-different with respect to the `loan_status` field?\n",
    "# Print either \"Meaningful\" or \"Not meaningful\"\n",
    "print(\"Meaningful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
