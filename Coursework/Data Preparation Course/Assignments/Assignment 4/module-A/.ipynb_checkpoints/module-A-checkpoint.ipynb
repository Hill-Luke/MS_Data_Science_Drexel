{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module submission header\n",
    "### Submission preparation instructions \n",
    "_Completion of this header is mandatory, subject to a 2-point deduction to the assignment._ Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. You must fill out all group member Names and Drexel email addresses in the below markdown list, under header __Module submission group__. It is required to fill out descriptive notes pertaining to any tutoring support received in the completion of this submission under the __Additional submission comments__ section at the bottom of the header. If no tutoring support was received, leave NA in place. You may as well list other optional comments pertaining to the submission at bottom. _Any distruption of this header's formatting will make your group liable to the 2-point deduction._\n",
    "\n",
    "### Module submission group\n",
    "- Group member 1\n",
    "    - Name: NA\n",
    "    - Email: NA\n",
    "- Group member 2\n",
    "    - Name: NA\n",
    "    - Email: NA\n",
    "- Group member 3\n",
    "    - Name: NA\n",
    "    - Email: NA\n",
    "- Group member 4\n",
    "    - Name: NA\n",
    "    - Email: NA\n",
    "\n",
    "### Additional submission comments\n",
    "- Tutoring support received: NA\n",
    "- Other (other): NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Group 4\n",
    "\n",
    "## Module A _(46 points)_\n",
    "For this assignment your work will set up a toolkit for plain text enhancement and summarization that can be reused later. Specifically, you'll use an API service known as 'Wikifier' which embeds hyperlink references to encyclopedia articles.\n",
    "\n",
    "Throughout this problem, we're going to be working with the Wikifier API, which is \"a web service that takes a text document as input and annotates it with links to relevant Wikipedia concepts\". So, before we can begin with the actual work, it's necessary to request access to this API at the following link: http://wikifier.org/info.html. Read this documentation and familiarize yourself with it, and make sure to register for a `userKey`.\n",
    "Store your `userKey` in the below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "USER_KEY = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A1.__ _(7 points)_ We're going to make requests to Wikifier. For this, complete the below function that takes a block of text and Wikifier API `KEY` as input, and outputs the JSON response given by the Wikification API (per the following specifications) interpreted as a Python object (deserialized). \n",
    "\n",
    "__Important__: For full credit you must read the Wikifier docs: http://wikifier.org/info.html and determine how to build a URL that sets the `'applyPageRankSqThreshold'` field to `True` whenever the `threshold` parameter is non-zero, which should be used to parameterize the corresponding `'pageRankSqThreshold'` field alongside the `language` parameter (for the `'lang'` field), and `KEY` for the `'userKey'` field and `text` for `'text'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1:Function(7/7)\n",
    "\n",
    "def get_wikifier_response(text, KEY, threshold = 0.8, language = 'en'):\n",
    "    \n",
    "    #---your code starts here---\n",
    "    \n",
    "    #---your code stops here---\n",
    "\n",
    "    return(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output could be:\n",
    "```\n",
    "(dict_keys(['title', 'url', 'lang', 'pageRank', 'cosine', 'secLang', 'secTitle', 'secUrl', 'wikiDataItemId', 'wikiDataClasses', 'dbPediaTypes', 'dbPediaIri', 'supportLen', 'support']),\n",
    " [([(0, 23)],\n",
    "   'Colonization of the Moon',\n",
    "   'http://en.wikipedia.org/wiki/Colonization_of_the_Moon'),\n",
    "  ([(16, 23),\n",
    "    (20, 23),\n",
    "    (128, 138),\n",
    "    (131, 138),\n",
    "    (135, 138),\n",
    "    (289, 296),\n",
    "    (293, 296)],\n",
    "   'Moon',\n",
    "   'http://en.wikipedia.org/wiki/Moon')])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1:SanityCheck \n",
    "\n",
    "test_wiki = get_wikifier_response(\"\".join([\"Colonization of the Moon is a concept \",\n",
    "                                           \"employed by some proposals of establishing \",\n",
    "                                           \"permanent human settlement or robotic presence on \",\n",
    "                                           \"the Moon, the closest astronomical body to Earth, \",\n",
    "                                           \"and the Earth's only natural satellite.\",\n",
    "                                           \"For a first permanent human space colony \",\n",
    "                                           \"or settlement the choice of the Moon \",\n",
    "                                           \"would benefit from its proximity to Earth.\"]), \n",
    "                                  USER_KEY)\n",
    "(test_wiki['annotations'][0].keys(), \n",
    " [([(sup['chFrom'], sup['chTo']) for sup in z['support']], \n",
    "   z['title'], z['url']) for z in test_wiki['annotations']][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A2.__ _(7 points)_ Now, supposing we wanted to keep track of this text's information alongside others, we'd first want to make sure our data access is simple and reusable, and don't want to cause any server problems for Wikifier. So, write a function called `get_wikification(text_file_path, KEY)` that accepts a `\"path_to/text_file.txt\"` (assuming a `'.txt'` extension) and a Wikifier `userKey`.\n",
    "\n",
    "Your code should load any target text and apply the `get_wikifier_response()` function from __A1__. Make sure your code checks for the availability of a previously-accessed response at the corresponding location: `\"path_to/wiki_file.json\"` (modified to a `'.json'` extension), which should just be re-loaded from your most recent call to the API, and flushed (deleted) manually if/when your code in __A1__ is at any point revised. \n",
    "\n",
    "Note: aside from specifying the `text` and `KEY`, your code should leave all other `get_wikifier_response` parameters as their defaults to meet the target output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2:Function(7/7)\n",
    "\n",
    "import os, json, re\n",
    "\n",
    "def get_wikification(text_file_path, KEY):\n",
    "\n",
    "    ## first, you must convert the provided text path into\n",
    "    ## the specified path for a .json object response from Wikifier\n",
    "    json_file_path = \"\"\n",
    "\n",
    "    #---your code starts here---\n",
    "\n",
    "    #---your code stops here---\n",
    "\n",
    "    # check to see if the text's file exists\n",
    "    if os.path.exists(json_file_path):\n",
    "        # load any pre-existing data\n",
    "        wiki = json.load(open(json_file_path))\n",
    "\n",
    "    else:\n",
    "        ## load the text and use this with your function from A1\n",
    "        ## to get the wikifier response and store the content on disk\n",
    "\n",
    "        #---your code starts here---\n",
    "\n",
    "        #---your code stops here---\n",
    "        \n",
    "    return wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output could be:\n",
    "```\n",
    "[(79, 'World War I', 'http://en.wikipedia.org/wiki/World_War_I'),\n",
    " (5, 'Latin', 'http://en.wikipedia.org/wiki/Latin'),\n",
    " (7, 'Europe', 'http://en.wikipedia.org/wiki/Europe'),\n",
    " (2, 'Nuclear weapon', 'http://en.wikipedia.org/wiki/Nuclear_weapon'),\n",
    " (32, 'Washington, D.C.', 'http://en.wikipedia.org/wiki/Washington,_D%2eC%2e')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2:SanityCheck\n",
    "\n",
    "unknown_file_path = \"./data/unknown.txt\"\n",
    "unknown_wiki = get_wikification(unknown_file_path, USER_KEY)\n",
    "\n",
    "[(len(z['support']), z['title'], z['url']) for z in unknown_wiki['annotations']][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A3.__ _(6 points)_ Now, to work with the Wikifier output we'll need to go through a few steps. The annotations (embedded links) provided by Wikifer reference specific document indices, i.e., for words (and their tokenization) and for characters. We'll work on the character level because it's more precise. To get this off of the ground, make a function called `build_doc(wiki)` that takes a Wikifier output (`wiki`) and builds up the original document from the `wiki['words']` and `wiki['spaces']` fields. \n",
    "\n",
    "\\[__Hint.__ These two fields alternate,  with `wiki['spaces']` having exactly one more element than `wiki['words']`, i.e., a rebuilt document will join the elements of the two with the first element coming from `wiki['spaces']`\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3:Function(6/6)\n",
    "\n",
    "def build_doc(wiki):\n",
    "    doc = []\n",
    "    \n",
    "    #---your code starts here---\n",
    "        \n",
    "    #---your code stops here---\n",
    "        \n",
    "    doc = \"\".join(doc)    \n",
    "    \n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "Mannie, at Mike's request, attends an anti-Authority meeting with a hidden recorder. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3:SanityCheck\n",
    "\n",
    "doc = build_doc(unknown_wiki)\n",
    "print(doc[:85])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A4.__ _(6 points)_ Now that we can get the document back together we'll also want to collect the links to insert them as annotations. So complete the below function called `get_links(wiki)` that processes the `annotation` objects from the `wiki['annotations']` field (a list of `annotation` objects), and creates/outputs a data object called links, which is a list of tuples:\n",
    "```\n",
    "links = [(chFrom, chTo, hyperlink), ...]\n",
    "```\n",
    "Hyperlinks will come from `annotation[\"url\"]`, and the `chFrom` and `chTo` elements represent character ranges corresponding to embeddings of `annotation[\"url\"]` in the document. Note that there are multiple character ranges: one for each `support` object in `annotation[\"support\"]` (also a list).  Specifically, each `support` object in the annotation field has two character indices keyed as `support[\"chFrom\"]` and `support[\"chTo\"]` which designate a range (in character indices) over which the hyperlink might well be embedded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4:Function(6/6)\n",
    "\n",
    "def get_links(wiki):\n",
    "    links = []\n",
    "    \n",
    "    #---your code starts here---\n",
    "    \n",
    "    #---your code stops here---\n",
    "            \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output could be:\n",
    "```\n",
    "(382,\n",
    " [(0, (6, 6, 'http://en.wikipedia.org/wiki/World_War_I')),\n",
    "  (100, (1092, 1092, 'http://en.wikipedia.org/wiki/Washington,_D%2eC%2e')),\n",
    "  (200, (3867, 3868, 'http://en.wikipedia.org/wiki/COVID-19_pandemic')),\n",
    "  (300, (3575, 3581, 'http://en.wikipedia.org/wiki/Public_opinion'))])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4:SanityCheck\n",
    "\n",
    "links = get_links(unknown_wiki)\n",
    "len(links), [(i, link) for i, link in enumerate(links) if not i % 100][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A5.__ _(5 points)_ Your next job is to complete the `embed_link(doc, link)` function that takes the full document output from __A3__, and, a given link (list element) from __A4__'s output, produces an updated document with the hyperlink embedded across the specified character span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5:Function(5/5)\n",
    "\n",
    "def embed_link(doc, link):\n",
    "    \n",
    "    #---your code starts here---\n",
    "    \n",
    "    #---your code stops here---\n",
    "    \n",
    "    return(annotated_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```html\n",
    "Mannie, at Mike's request, attends an anti-Authority meeting with a hidden recorder. When police raid the gathering, Mannie flees with <a href=\"http://en.wikipedia.org/wiki/Wyoming\">Wyoming</a>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5:SanityCheck\n",
    "\n",
    "for i, link in enumerate(links):\n",
    "    if link[2] == \"http://en.wikipedia.org/wiki/Wyoming\":\n",
    "        annotated_doc = embed_link(doc[:142], link)\n",
    "        break\n",
    "print(annotated_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A6.__ _(4 points)_ If you haven't yet noticed, there are many link predictions which point to the same page. Embedding all of these together in our document not only won't be informative but simply won't be possible. As a simple first heuristic, complete the function below to filter the links we get from a given `wiki` so that only one embedding (text span) is maintained for each link, _corresponding to the longest span over which they were embedded_. Your job is to track these in the `longest_links` dictionary object, which should be keyed by the URLs, and have values equal to the list-rows returned by the `get_links` function. \n",
    "\n",
    "Note: since `sorted(longest_links.values())` is returned, your function necessarily returns a list where each URL only appears once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A6:Function(4/4)\n",
    "\n",
    "def filter_longest_links(wiki):\n",
    "    links = get_links(wiki)        \n",
    "    longest_links = {}\n",
    "    ## store only the longest embedding of each link (in characters)\n",
    "    \n",
    "    #---your code starts here---\n",
    "    \n",
    "    #---your code stops here---\n",
    "    \n",
    "    return sorted(longest_links.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output could be:\n",
    "```\n",
    "[(8, 9, 'http://en.wikipedia.org/wiki/Latin'),\n",
    " (35, 36, 'http://en.wikipedia.org/wiki/Europe'),\n",
    " (83, 83, 'http://en.wikipedia.org/wiki/Washington,_D%2eC%2e'),\n",
    " (102, 104, 'http://en.wikipedia.org/wiki/COVID-19_pandemic'),\n",
    " (135, 141, 'http://en.wikipedia.org/wiki/Wyoming'),\n",
    " (255, 263, 'http://en.wikipedia.org/wiki/Professor'),\n",
    " (255, 282, 'http://en.wikipedia.org/wiki/The_Moon_Is_a_Harsh_Mistress'),\n",
    " (326, 335, 'http://en.wikipedia.org/wiki/Hydroponics'),\n",
    " (337, 341, 'http://en.wikipedia.org/wiki/Wheat'),\n",
    " (355, 357, 'http://en.wikipedia.org/wiki/World_War_I')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A6:SanityCheck\n",
    "\n",
    "longest_links = filter_longest_links(unknown_wiki)\n",
    "longest_links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A7.__ _(6 points)_ The responses received from Wikifier are really only _predictions_ of where links should go. This means that multiple link predictions might span overlapping portions of source text. So, we'll have to make sure our code does some light decision making to avoid overlapping hyperlinks and broken html code. \n",
    "\n",
    "Your job now is to complete the `embed_links()` function, which will manage the link embedding process, particularly, the overlapping link problem. Specifically, your function _must_:\n",
    "\n",
    "1. Take a wikifier, `wiki`, response as input.\n",
    "2. Build the document using `build_doc()` and store its output as a string called `doc`\n",
    "3. Apply `get_links()` function, storing the `links` output \n",
    "4. _Reverse_ sort the `link`  by their ending points, i.e., `support[\"chTo\"]` values\n",
    "5. Loop through the _sorted_ `links` \n",
    "6. Conditionally use the `embed_link()` function to embed links into `doc` in the loop. Specifically, only embed a link if its `support[\"chTo\"]` value is less than the previous one's `support[\"chFrom\"]` value, or if the link to embed is the first in the loop.\n",
    "7. `return` the link-enhanced `doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A7:Function(6/6)\n",
    "\n",
    "def embed_links(wiki):\n",
    "    ## build the document, gather its links\n",
    "    ## and store only the longest embedding for each (in characters)\n",
    "    doc = build_doc(wiki)\n",
    "    links = get_links(wiki)        \n",
    "    longest_links = filter_longest_links(wiki)\n",
    "    ## sort the links from high to low by their second 'column'\n",
    "    \n",
    "    #---your code starts here---\n",
    "    \n",
    "    #---your code stops here---\n",
    "\n",
    "    ## you must keep track of the previously-entered link's starting index\n",
    "    prev_from = float(\"Inf\")\n",
    "    for link in sorted_links:\n",
    "        ## only embed if the current link doesn't overlap 'into'\n",
    "        ## the previously-entered link's starting index\n",
    "        \n",
    "        #---your code starts here---\n",
    "        \n",
    "        #---your code stops here---\n",
    "\n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your first paragraph's rendering should come close to the below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mannie, at Mike's request, attends [an](http://en.wikipedia.org/wiki/Europe) anti-Authority meeting with a hidden recorder[.](http://en.wikipedia.org/wiki/Washington,_D%2eC%2e) When police raid [the](http://en.wikipedia.org/wiki/COVID-19_pandemic) gathering, Mannie flees with [Wyoming](http://en.wikipedia.org/wiki/Wyoming) (\"Wyoh\") Knott, a political agitator, whom he introduces to Mike. They meet Mannie's former mentor, the elderly [](http://en.wikipedia.org/wiki/Professor)[Professor Bernardo de la Paz](</a>http://en.wikipedia.org/wiki/The_Moon_Is_a_Harsh_Mistress), who claims that Luna must stop exporting [hydroponic](http://en.wikipedia.org/wiki/Hydroponics) [grain](http://en.wikipedia.org/wiki/Wheat) to Earth or [its](http://en.wikipedia.org/wiki/World_War_I) ice-mines will soon be exhausted, leaving the Moon waterless. Joining the [cabal](http://en.wikipedia.org/wiki/Cabal), Mike calculates that without prevention, food riots [will occur](http://en.wikipedia.org/wiki/Gulf_War) in seven years and [cannibalism](http://en.wikipedia.org/wiki/Cannibalism) in nine. Wyoh and the Professor decide to start a revolution, and persuade Mannie to join after Mike calculates a one in seven chance of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A7:SanityCheck\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "annotated_doc = embed_links(unknown_wiki)\n",
    "annotated_doc = re.sub(\"\\n\", \"<br>\", annotated_doc)\n",
    "HTML(annotated_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A8.__ _(5 pts)_ It's time to package your code up so someone else can use it! Specifically, your goal here will be to place _all of the functions_ that you defined within this module into a file called `./wikifier.py`; doing so will technically create our very own _Python module_. When this is complete, you'll be able to operate your code's function by loading the module, i.e., `import wikifier`, and executing the two controller methods:\n",
    "\n",
    "- `wikification = wikifier.get_wikification(\"example_text.txt\", USER_KEY)`\n",
    "- `annotated_doc = wikifier.embed_links(wikification)`\n",
    "\n",
    "Note: Your `./wikifier.py` Python module must also contain any necessary module loads, and since it is being distributed for _others_ to use it absolutely must use relative file paths, assuming the `./data/` location for application data. \n",
    "\n",
    "Importantly, to write the contents of a cell to a file, your job is to utilize the `inspect` module, whose `inspect.getsource()` method may be applied to a function to get its source as a  string. Once as strings, you must concatenate the functions together&mdash;onto the module loads&mdash;while being sure to separate each function by two newlines (`\"\\n\\n\"`), for clarity. Note: for convenience, all of your functions are maintained in the `all_function` list object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A8:Inline(5/5)\n",
    "\n",
    "import inspect\n",
    "\n",
    "all_functions = [get_wikifier_response, get_wikification, build_doc, \n",
    "                 get_links, embed_link, filter_longest_links, embed_links]\n",
    "\n",
    "## start the module with the dependencies it must load\n",
    "module_script = \"import os, re, json, requests\\n\\n\"\n",
    "\n",
    "#---your code starts here---\n",
    "\n",
    "#---your code stops here---\n",
    "\n",
    "with open('wikifier.py', 'w') as f:\n",
    "    f.write(module_script)\n",
    "\n",
    "print(module_script[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output from the above should be identical to the text of the functions you've authored. Likewise, the below `SanityCheck` should produce the exact same output as __A7.__ Also, don't forget&mdash;TANSTAAFL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A8:SanityCheck\n",
    "\n",
    "import wikifier, importlib\n",
    "importlib.reload(wikifier)\n",
    "\n",
    "wikification = wikifier.get_wikification(unknown_file_path, USER_KEY)\n",
    "annotated_doc = wikifier.embed_links(wikification)\n",
    "HTML(re.sub(\"\\n\", \"<br>\", annotated_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
