{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module submission header\n",
    "### Submission preparation instructions \n",
    "_Completion of this header is mandatory, subject to a 2-point deduction to the assignment._ Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. You must fill out all group member Names and Drexel email addresses in the below markdown list, under header __Module submission group__. It is required to fill out descriptive notes pertaining to any tutoring support received in the completion of this submission under the __Additional submission comments__ section at the bottom of the header. If no tutoring support was received, leave NA in place. You may as well list other optional comments pertaining to the submission at bottom. _Any distruption of this header's formatting will make your group liable to the 2-point deduction._\n",
    "\n",
    "### Module submission group\n",
    "- Group member 1\n",
    "    - Name: Luke Hill\n",
    "    - Email: lh967@drexel.edu\n",
    "\n",
    "\n",
    "### Additional submission comments\n",
    "- Tutoring support received: NA\n",
    "- Other (other): NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Group 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem C _(50 points)_\n",
    "\n",
    "This problem deals with finding \"pangrams\" in text. A pangram is a sentence containing all 26 letters of the alphabet. `x` and `y` in the cell below are example sentences, `x` is a pangram, `y` is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Jim quickly realized that the beautiful gowns are expensive.\"\n",
    "y = \"This sentence is most certainly not a pangram.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C1.__ _(5 points)_ Complete the function, `indices()`, that takes a string as input and outputs a list of the index numbers where each lowercase character from the English alphabet occurs first (only) in the string. Note: your function should `break` and `return` the list if `26` characters are found.\n",
    "\n",
    "[__Hint:__ you must keep track of which characters have been `found`, and a `set` could help with this. Also, you can compare letters like numbers. For example, `char >= \"a\"` is a valid conditional statement. You can use this to check whether characters in a string are letters of the alphabet.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1:Function(5/5) \n",
    "\n",
    "def indices(text):\n",
    "    first_indices = []; text = text.lower()\n",
    "    \n",
    "    # Define a set to keep track of lowercase characters that have been found\n",
    "    found_chars = set()\n",
    "\n",
    "    for index, char in enumerate(text):\n",
    "        if char.islower() and char not in found_chars:\n",
    "            first_indices.append(index)\n",
    "            found_chars.add(char)\n",
    "\n",
    "            # Break and return if all 26 characters are found\n",
    "            if len(found_chars) == 26:\n",
    "                return first_indices\n",
    "\n",
    "    return first_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "[0, 1, 2, 4, 5, 7, 8, 9, 10, 12, 13, 14, 17, 19, 21, 22, 30, 36, 40, 41, 42, 43, 44, 51, 52, 57]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4, 5, 7, 8, 9, 10, 12, 13, 14, 17, 19, 21, 22, 30, 36, 40, 41, 42, 43, 44, 51, 52, 57]\n"
     ]
    }
   ],
   "source": [
    "# C1:SanityCheck\n",
    "\n",
    "first_indices = indices(x)\n",
    "print(first_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C2.__ _(3 points)_ Now complete the function `verify()`, which must take a string as input and use the output of the `indices()` function to check if the string is a pangram, where the output of `verify()` should should be boolean `True` or `False` named `has_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2:Function(3/3)\n",
    "\n",
    "def verify(text):\n",
    "    has_all = False\n",
    "    first_indices = indices(text)\n",
    "    \n",
    "    if len(first_indices) == 26:\n",
    "        has_all=True\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return has_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "(True, False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C2:SanityCheck\n",
    "\n",
    "verify(x), verify(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C3:__ _(2 points)_ Now complete the below function named `tiny_verify()` that performs the check in a single line of code&mdash;_without using `indices()`_. [__Hint:__ Use a comprehension.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C3:Function(2/2)\n",
    "\n",
    "def tiny_verify(text):\n",
    "    output = set()\n",
    "    has_all = False\n",
    "\n",
    "    for char in text:\n",
    "        \n",
    "        output.add(text.index(char))\n",
    "\n",
    "        if len(output) >= 26:\n",
    "            has_all = True\n",
    "        else:\n",
    "            has_all = False\n",
    "    return has_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "(True, False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C2:SanityCheck\n",
    "\n",
    "tiny_verify(x), tiny_verify(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C4.__ _(5 points)_ Now complete the `verify_missing()` by filling the `letters` set with any alphabetic characters that appear in the purported pangram. This version will return a list of missing letters instead of a boolean value, with the list of missing characters computed as a set difference against the `all_letters` set. [__Hint:__ Use the string containing all the letters in the alphabet, imported from the `string` module.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4:Function(5/5)\n",
    "\n",
    "from string import ascii_lowercase as ascii_letters\n",
    "\n",
    "def verify_missing(text):\n",
    "    all_letters = set(ascii_letters)\n",
    "    letters = set(text.lower())\n",
    "    return list(all_letters.difference(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "([], ['z', 'v', 'k', 'd', 'u', 'j', 'w', 'b', 'f', 'x', 'q'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], ['b', 'k', 'f', 'x', 'z', 'j', 'u', 'q', 'w', 'v', 'd'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_missing(x), verify_missing(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The letters are out of order but seem to match the expected output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C5.__ _(5 points)_ Now iterate through the loaded [list of pangrams](http://clagnut.com/blog/2380/) in `data/pangrams.txt` and `verify` which are actually pangrams. Store any incomplete sentences (that _don't_ `verify`) in the `imposters` list, which forms the function's output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C5:Function(5/5)\n",
    "\n",
    "potential_pangrams = open(\"data/pangrams.txt\", \"r\").readlines()\n",
    "potential_pangrams = [sentence.strip().lower() for sentence in potential_pangrams]\n",
    "\n",
    "def evaluate_pangrams(sentences):\n",
    "    imposters = []\n",
    "    alphabet = set('abcdefghijklmnopqrstuvwxyz')\n",
    "   \n",
    "    for line in sentences:\n",
    "        if set(line)>=alphabet:\n",
    "            pass\n",
    "        else:\n",
    "            imposters.append(line)\n",
    "    return imposters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "Faulty pangram: \n",
    "Show mangled quartz flip vibe exactly.\n",
    "Missing letters: \n",
    "['k', 'j']\n",
    "\n",
    "Faulty pangram: \n",
    "Unamazingly, this six-word pangram is questionable!\n",
    "Missing letters: \n",
    "['c', 'v', 'k', 'j', 'f']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faulty pangram: \n",
      "show mangled quartz flip vibe exactly.\n",
      "Missing letters: \n",
      "['j', 'k']\n",
      "\n",
      "Faulty pangram: \n",
      "unamazingly, this six-word pangram is questionable!\n",
      "Missing letters: \n",
      "['f', 'k', 'j', 'c', 'v']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# C5:SanityCheck\n",
    "\n",
    "imposters = evaluate_pangrams(potential_pangrams)\n",
    "for sentence in imposters:\n",
    "    print(\"Faulty pangram: \")\n",
    "    print(sentence)\n",
    "    print(\"Missing letters: \")\n",
    "    print(verify_missing(sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C6:__ _(3 points)_ Now complete the function below to use the output from the `verify()` function to fix the failed pangrams by any means necessary, and then collect the original and fixed sentences in a list of tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1330813355.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 29\u001b[1;36m\u001b[0m\n\u001b[1;33m    imposters_fixed.\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# C6:Function(3/3)\n",
    "\n",
    "import re\n",
    "import random as ra\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def tokenize(text, space = True, wordchars = \"a-zA-Z0-9-'\"):\n",
    "    tokens = []\n",
    "    for token in re.split(\"([\"+wordchars+\"]+)\", text):\n",
    "        if not space:\n",
    "            token = re.sub(\"[ ]+\", \"\", token)\n",
    "        if not token:\n",
    "            continue\n",
    "        if re.search(\"[\"+wordchars+\"]\", token):\n",
    "            tokens.append(token)\n",
    "        else: \n",
    "            tokens.extend(token)\n",
    "    return tokens\n",
    "\n",
    "def fix_pangrams(sentences, seed = 511):\n",
    "    word_counts = Counter([t for sentence in sentences for t in tokenize(sentence)])\n",
    "    word_index = defaultdict(list)\n",
    "    for w in word_counts: word_index[w[0]].append(w)\n",
    "    imposters_fixed = []\n",
    "    ra.seed(seed)\n",
    "    \n",
    "    for line in sentences:\n",
    "        if line in imposters:\n",
    "            imposters_fixed.\n",
    "            \n",
    "    #---your code stops here---\n",
    "    \n",
    "    return imposters_fixed\n",
    "fix_pangrams(potential_pangrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output could be:\n",
    "```\n",
    "Faulty pangram: \n",
    "show mangled quartz flip vibe exactly.\n",
    "Fixed pangram:\n",
    "show mangled quartz flip vibe exactly; kvetching jets.\n",
    "\n",
    "Faulty pangram: \n",
    "unamazingly, this six-word pangram is questionable!\n",
    "Fixed pangram:\n",
    "unamazingly, this six-word pangram is questionable; chimp veldt kazakh jonquils flip!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note from Luke:__\n",
    "Gonna take the loss on this one. I have no idea what you're expecting with this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fix_pangrams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lukeh\\Desktop\\Grad School\\MS_Data_Science_Drexel\\Data Prep\\Assignments\\Module C\\module-C\\module-C.ipynb Cell 30\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# C6:SanityCheck\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m imposters_fixed \u001b[39m=\u001b[39m fix_pangrams(potential_pangrams)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence, fixed \u001b[39min\u001b[39;00m imposters_fixed:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFaulty pangram: \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fix_pangrams' is not defined"
     ]
    }
   ],
   "source": [
    "# C6:SanityCheck\n",
    "\n",
    "imposters_fixed = fix_pangrams(potential_pangrams)\n",
    "for sentence, fixed in imposters_fixed:\n",
    "    print(\"Faulty pangram: \")\n",
    "    print(sentence)\n",
    "    print(\"Fixed pangram:\")\n",
    "    print(fixed)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C7.__ _(5 points)_ In the cell below, complete the metadata munging job using the information about the set of books in the `books_available` string. Assuming there may be many more books and that their information can be provided in the same format, create a data object that holds the book authors and titles associated to each book number, and writes the metadata as a JSON file in the `data/books/` directory using the following schema:\n",
    "\n",
    "`\n",
    "books = {\n",
    "    BookNumber: {\n",
    "        'author': AuthorName\n",
    "        'title': BookTitle,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('84',\n",
       "  'Frankenstein, or the Modern Prometheus',\n",
       "  'Mary Wollstonecraft (Godwin) Shelley'),\n",
       " ('98', 'A Tale of Two Cities', 'Charles Dickens'),\n",
       " ('161', 'Sense and Sensibility', 'Jane Austen'),\n",
       " ('730', \"Oliver Twist or the Parish Boy's Progress\", 'Charles Dickens'),\n",
       " ('768', 'Wuthering Heights', 'Emily Brontë'),\n",
       " ('1322', 'Leaves of Grass', 'Walt Whitman'),\n",
       " ('1342', 'Pride and Prejudice', 'Jane Austen'),\n",
       " ('1400', 'Great Expectations', 'Charles Dickens'),\n",
       " ('2701', 'Moby Dick', 'or the Whale'),\n",
       " ('4300', 'Ulysses', 'James Joyce')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "books_available = \"\"\"\n",
    "84.txt; Frankenstein, or the Modern Prometheus; Mary Wollstonecraft (Godwin) Shelley\n",
    "98.txt; A Tale of Two Cities; Charles Dickens\n",
    "161.txt; Sense and Sensibility; Jane Austen\n",
    "730.txt; Oliver Twist or the Parish Boy's Progress; Charles Dickens\n",
    "768.txt; Wuthering Heights; Emily Brontë\n",
    "1322.txt; Leaves of Grass; Walt Whitman\n",
    "1342.txt; Pride and Prejudice; Jane Austen\n",
    "1400.txt; Great Expectations; Charles Dickens\n",
    "2701.txt; Moby Dick; or the Whale; Herman Melville\n",
    "4300.txt; Ulysses; James Joyce\n",
    "\"\"\"\n",
    "\n",
    "books = {}\n",
    "books_metadata = \"data/books/metadata.json\"\n",
    "\n",
    "# Separating out the lines\n",
    "book_lines = books_available.strip().split('\\n')\n",
    "\n",
    "# Parsing the columns\n",
    "for line in book_lines:\n",
    "    parts = line.split('; ')\n",
    "    book_number = parts[0].strip('.txt')\n",
    "    book_title = parts[1]\n",
    "    book_author = parts[2]\n",
    "    \n",
    "    # Create a dictionary for the current book\n",
    "    book_info = {\n",
    "        'Title': book_title,\n",
    "        'Author': book_author\n",
    "    }\n",
    "    \n",
    "    # Add the book info to the books dictionary using the book_number as the key\n",
    "    books[book_number] = book_info\n",
    "\n",
    "# Convert the books dictionary to a list of tuples\n",
    "books = [\n",
    "    (book_num, book_info['Title'], book_info['Author'])\n",
    "    for book_num, book_info in books.items()\n",
    "]\n",
    "\n",
    "# Save the metadata to a JSON file\n",
    "with open(books_metadata, \"w\") as json_file:\n",
    "    json.dump(books, json_file, indent=4)\n",
    "\n",
    "# Print the books list (optional)\n",
    "books\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, you _could_ literally start typing:\n",
    "```\n",
    "books = {84 : {'title': 'Frankenstein, or the Modern Prometheus',\n",
    "               'author': 'Mary Wollstonecraft (Godwin) Shelley'}, ...}\n",
    "```\n",
    "but that would miss the point. Instead, you should use regular expressions to process the `books_available` object automatically by any convenient delimiters to produce the target object structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C8.__ _(4 points)_ Now complete the `sentokenize(text)` function using the `re` (regular expressions) module to split the book text into sentences using the `re.split(pattern, string)` function. The function must take a document and break it into 'sentences' (sentence-like strings), and then break these into lists of tokens within the larger `sentences` list.\n",
    "\n",
    "Note: you can efficiently use the below pattern to obtain the desired output for sentokenization:\n",
    "- `\"(\\s*(?<=[\"+delims+\"][^\"+sentchars+\"])\\s*)\"` \n",
    "    \n",
    "Additionally, ensure each `sentence` stored from the output of the sentokenization pattern is non-empty and processed by `tokenize` before being placed into the `sentences` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C8:Function(4/4)\n",
    "import re \n",
    "def sentokenize(text, space = False, delims = \".?!\", sentchars = \"a-zA-Z0-9-',;:\"):\n",
    "    sentences = []\n",
    "# Define the regular expression pattern for sentence splitting\n",
    "    pattern = r\"(\\s*(?<=[\" + delims + \"][^\" + sentchars + \"])\\s*)\"\n",
    "\n",
    "    # Use re.split to split the text into sentences\n",
    "    sentence_list = re.split(pattern, text)\n",
    "\n",
    "    # Process each sentence and tokenize it\n",
    "    for sentence in sentence_list:\n",
    "        # Check if the sentence is non-empty\n",
    "        if sentence.strip():\n",
    "            # Tokenize the sentence by splitting on spaces\n",
    "            tokens = sentence.split() if space else [sentence]\n",
    "            sentences.append(tokens)\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "['\\nCompletion of this header is mandatory, subject to a 2-point deduction to the assignment. \\n',\n",
    " \"Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. \\n\",\n",
    " 'You must fill out all group member Names and Drexel email addresses in the below markdown list, \\nunder header Module submission group. ',\n",
    " 'It is required to fill out descriptive notes pertaining to \\nany tutoring support received in the completion of this submission \\nunder the Additional submission comments section at the bottom of the header. \\n',\n",
    " 'If no tutoring support was received, leave NA in place. \\n',\n",
    " 'You may as well list other optional comments pertaining to the submission at bottom. \\n',\n",
    " \"Any distruption of this header's formatting will make your group liable to the 2-point deduction.\\n\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nCompletion of this header is mandatory, subject to a 2-point deduction to the assignment.',\n",
       " \"Only add plain text in the designated areas, i.e., replacing the relevant 'NA's.\",\n",
       " 'You must fill out all group member Names and Drexel email addresses in the below markdown list, \\nunder header Module submission group.',\n",
       " 'It is required to fill out descriptive notes pertaining to \\nany tutoring support received in the completion of this submission \\nunder the Additional submission comments section at the bottom of the header.',\n",
       " 'If no tutoring support was received, leave NA in place.',\n",
       " 'You may as well list other optional comments pertaining to the submission at bottom.',\n",
       " \"Any distruption of this header's formatting will make your group liable to the 2-point deduction.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C8:SanityCheck\n",
    "\n",
    "test_sentences = sentokenize(\"\"\"\n",
    "Completion of this header is mandatory, subject to a 2-point deduction to the assignment. \n",
    "Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. \n",
    "You must fill out all group member Names and Drexel email addresses in the below markdown list, \n",
    "under header Module submission group. It is required to fill out descriptive notes pertaining to \n",
    "any tutoring support received in the completion of this submission \n",
    "under the Additional submission comments section at the bottom of the header. \n",
    "If no tutoring support was received, leave NA in place. \n",
    "You may as well list other optional comments pertaining to the submission at bottom. \n",
    "Any distruption of this header's formatting will make your group liable to the 2-point deduction.\n",
    "\"\"\")\n",
    "\n",
    "[\"\".join(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C9.__ _(3 points)_ Now use the `sentokenize` function to complete the `get_pangrams(book_num)` function to determine which sentences in a given book are pangrams. The output of this function should be a tuple, continaing the list of found `pangrams` and the total number of sentencs (`num_sentences`) in the book. [Hint: don't forget to `.lower()` your sentences before attempting pangram verification!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C9:Function(3/7)\n",
    "\n",
    "def get_pangrams(book_num):\n",
    "    pangrams = []\n",
    "    num_sentences = 0\n",
    "\n",
    "    with open(\"data/books/\" + str(book_num) + \".txt\", \"r\") as f:\n",
    "        for sentence in sentokenize(f.read()):\n",
    "            sentence = ' '.join(sentence).lower()\n",
    "            alphabet = set('abcdefghijklmnopqrstuvwxyz')\n",
    "\n",
    "            # Check if the sentence is a pangram\n",
    "            if set(sentence) >= alphabet:\n",
    "                pangrams.append(sentence)\n",
    "\n",
    "            num_sentences += 1\n",
    "\n",
    "    return pangrams, num_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "8363 1 Every town-gate and village taxing-house had its band of\n",
    "citizen-patriots, with their national muskets in a most explosive state\n",
    "of readiness, who stopped all comers and goers, cross-questioned them,\n",
    "inspected their papers, looked for their names in lists of their own,\n",
    "turned them back, or sent them on, or stopped them and laid them in\n",
    "hold, as their capricious judgment or fancy deemed best for the dawning\n",
    "Republic One and Indivisible, of Liberty, Equality, Fraternity, or\n",
    "Death.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8364 1 every town-gate and village taxing-house had its band of\n",
      "citizen-patriots, with their national muskets in a most explosive state\n",
      "of readiness, who stopped all comers and goers, cross-questioned them,\n",
      "inspected their papers, looked for their names in lists of their own,\n",
      "turned them back, or sent them on, or stopped them and laid them in\n",
      "hold, as their capricious judgment or fancy deemed best for the dawning\n",
      "republic one and indivisible, of liberty, equality, fraternity, or\n",
      "death.\n"
     ]
    }
   ],
   "source": [
    "# C9:SanityCheck\n",
    "\n",
    "book_results = get_pangrams(98)\n",
    "print(book_results[1], len(book_results[0]), \"\".join(book_results[0][0]) if book_results[0] else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C10.__ _(8 points)_ Now complete the below function to determine who is the pangrammiest author and what the pangrammiest book is, as determined by most pangrams per sentence. For this part, you must use the `defaultdict`s to store data in the `pangrams_by_author` and `pangrams_by_book` objects.  The first object (`pangrams_by_author`)  should be keyed by `author`, and the second object (`pangrams_by_book`) should be keyed by `(author, book_num)`-tuples. Each object's values should be total list of pangrams and sentence numbers for each grouping of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C10:Function(4/8)\n",
    "\n",
    "def collect_pangrams(books):\n",
    "    pangrams_by_author = defaultdict(lambda: [[], 0])\n",
    "    pangrams_by_book = defaultdict(lambda: [[], 0])\n",
    "\n",
    "    #---your code starts here---\n",
    "            \n",
    "    #---your code stops here---\n",
    "    \n",
    "    return pangrams_by_author, pangrams_by_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_book_text(book_num):\n",
    "    with open(f\"data/books/{book_num}.txt\", \"r\") as file:\n",
    "        return file.read()\n",
    "def is_pangram(sentence):\n",
    "    alphabet = set('abcdefghijklmnopqrstuvwxyz')\n",
    "    sentence = sentence.lower()\n",
    "    return set(sentence) >= alphabet\n",
    "\n",
    "def collect_pangrams(books):\n",
    "    pangrams_by_author = defaultdict(lambda: [[], 0])\n",
    "    pangrams_by_book = defaultdict(lambda: [[], 0])\n",
    "\n",
    "    for book_num, book_title, author in books:\n",
    "        sentences = sentokenize(get_book_text(book_num))\n",
    "        pangram_count = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if is_pangram(' '.join(sentence).lower()):\n",
    "                pangram_count += 1\n",
    "                pangrams_by_author[author][0].append(' '.join(sentence))\n",
    "                pangrams_by_book[(author, book_num)][0].append(' '.join(sentence))\n",
    "\n",
    "        num_sentences = len(sentences)\n",
    "        pangrams_by_author[author][1] += num_sentences\n",
    "        pangrams_by_book[(author, book_num)][1] = num_sentences\n",
    "\n",
    "    return pangrams_by_author, pangrams_by_book\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "(2, 26836)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 26842)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C10:SanityCheck\n",
    "\n",
    "pangrams_by_author, pangrams_by_book = collect_pangrams(books)\n",
    "len(pangrams_by_author[\"Charles Dickens\"][0]), pangrams_by_author[\"Charles Dickens\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the function below to operate on the `pangrams_by_author` and `pangrams_by_book` objects and compute the portion of all sentences that were pangrams for each author-grouping and book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C10:Function(4/8)\n",
    "\n",
    "def compute_pangram_rates(pangrams_by_author, pangrams_by_book):\n",
    "    authors_pangrams_per_sentence, books_pangrams_per_sentence = [], []\n",
    "\n",
    "    # Calculate authors' pangram rates\n",
    "    for author, (pangrams, total_sentences) in pangrams_by_author.items():\n",
    "        pangram_rate = len(pangrams) / total_sentences\n",
    "        authors_pangrams_per_sentence.append((author, pangram_rate))\n",
    "\n",
    "    # Calculate books' pangram rates\n",
    "    for (author, book_num), (pangrams, total_sentences) in pangrams_by_book.items():\n",
    "        pangram_rate = len(pangrams) / total_sentences\n",
    "        books_pangrams_per_sentence.append(((author, book_num), pangram_rate))\n",
    "\n",
    "    return authors_pangrams_per_sentence, books_pangrams_per_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "\n",
    "```\n",
    "In order of decreasing pangrammyness, the authors are: \n",
    "[(0.00234375, 'Walt Whitman'),\n",
    " (0.0004151617054842861, 'James Joyce'),\n",
    " (0.0003994407829039345, 'Herman Melville'),\n",
    " (0.00034928396786587494, 'Emily Brontë'),\n",
    " (0.00023796303640834457, 'Jane Austen'),\n",
    " (7.452675510508272e-05, 'Charles Dickens'),\n",
    " (0.0, 'Mary Wollstonecraft (Godwin) Shelley')]\n",
    "\n",
    "In order of decreasing pangrammyness, the books are: \n",
    "[(0.00234375, 'Leaves of Grass'),\n",
    " (0.0004233700254022015, 'Pride and Prejudice'),\n",
    " (0.0004151617054842861, 'Ulysses'),\n",
    " (0.0003994407829039345, 'Moby Dick; or the Whale'),\n",
    " (0.00034928396786587494, 'Wuthering Heights'),\n",
    " (0.0001268874508311128, \"Oliver Twist or the Parish Boy's Progress\"),\n",
    " (0.00011957431543704412, 'A Tale of Two Cities'),\n",
    " (0.0, 'Great Expectations'),\n",
    " (0.0, 'Sense and Sensibility'),\n",
    " (0.0, 'Frankenstein, or the Modern Prometheus')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In order of decreasing pangrammyness, the authors are: \n",
      "[('or the Whale', 0.0003982873643333665),\n",
      " ('Walt Whitman', 0.00234375),\n",
      " ('Mary Wollstonecraft (Godwin) Shelley', 0.0),\n",
      " ('Jane Austen', 0.00023784983746927773),\n",
      " ('James Joyce', 0.0004067189978443893),\n",
      " ('Emily Brontë', 0.00034928396786587494),\n",
      " ('Charles Dickens', 7.4510096118024e-05)]\n",
      "\n",
      "In order of decreasing pangrammyness, the books are: \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lukeh\\Desktop\\Grad School\\MS_Data_Science_Drexel\\Data Prep\\Assignments\\Module C\\module-C\\module-C.ipynb Cell 50\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X64sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pprint(\u001b[39msorted\u001b[39m(authors_pangrams_per_sentence, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X64sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIn order of decreasing pangrammyness, the books are: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X64sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pprint([(x[\u001b[39m0\u001b[39m], books[x[\u001b[39m1\u001b[39m]][\u001b[39m'\u001b[39m\u001b[39mTitle\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(books_pangrams_per_sentence, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)])\n",
      "\u001b[1;32mc:\\Users\\lukeh\\Desktop\\Grad School\\MS_Data_Science_Drexel\\Data Prep\\Assignments\\Module C\\module-C\\module-C.ipynb Cell 50\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X64sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pprint(\u001b[39msorted\u001b[39m(authors_pangrams_per_sentence, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X64sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIn order of decreasing pangrammyness, the books are: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#X64sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pprint([(x[\u001b[39m0\u001b[39m], books[x[\u001b[39m1\u001b[39;49m]][\u001b[39m'\u001b[39m\u001b[39mTitle\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(books_pangrams_per_sentence, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)])\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not float"
     ]
    }
   ],
   "source": [
    "# C10:SanityCheck\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "authors_pangrams_per_sentence, books_pangrams_per_sentence = compute_pangram_rates(pangrams_by_author, pangrams_by_book)\n",
    "\n",
    "print(\"In order of decreasing pangrammyness, the authors are: \")\n",
    "pprint(sorted(authors_pangrams_per_sentence, reverse=True))\n",
    "\n",
    "print(\"\\nIn order of decreasing pangrammyness, the books are: \")\n",
    "pprint([(x[0], books[x[1]]['Title']) for x in sorted(books_pangrams_per_sentence, reverse=True)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C11.__ _(7 points)_ Finally, complete the below function to compute the most efficient pangram and its author and book, as determined by fewest characters per pangram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C11:Function(7/7)\n",
    "\n",
    "def most_efficient_pangram(pangrams_by_book):\n",
    "    most_efficient_author =  None\n",
    "    most_efficient_book = None\n",
    "    most_efficient_title = None\n",
    "    least_characters = float(\"Inf\")\n",
    "    best_pangram = \"NA\"\n",
    "\n",
    "    #---your code starts here---\n",
    "    \n",
    "    #---your code stops here---\n",
    "                \n",
    "    return (most_efficient_book, most_efficient_author, \n",
    "            most_efficient_title, least_characters, best_pangram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_efficient_pangram(pangrams_by_book, books_metadata):\n",
    "    most_efficient_author =  None\n",
    "    most_efficient_book = None\n",
    "    most_efficient_title = None\n",
    "    least_characters = float(\"Inf\")\n",
    "    best_pangram = \"NA\"\n",
    "\n",
    "    for (author, book_num), (pangrams, num_sentences) in pangrams_by_book.items():\n",
    "        if num_sentences == 0:\n",
    "            continue  # Skip books with no sentences\n",
    "\n",
    "        characters_per_pangram = sum(len(pangram) for pangram in pangrams) / len(pangrams) if len(pangrams) > 0 else 0\n",
    "\n",
    "        if characters_per_pangram < least_characters:\n",
    "            least_characters = characters_per_pangram\n",
    "            most_efficient_author = author\n",
    "            most_efficient_book = book_num\n",
    "            most_efficient_title = books_metadata[int(book_num)]['Title']  # Convert book_num to int\n",
    "            best_pangram = min(pangrams, key=len)\n",
    "\n",
    "    return (most_efficient_book, most_efficient_author, most_efficient_title, least_characters, best_pangram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, your output should be:\n",
    "```\n",
    "The best pangramming author, Charles Dickens, wrote a 223-character pangram in the book: \n",
    "\"Oliver Twist or the Parish Boy's Progress\" (booknumber: 730)\n",
    "\n",
    "This pangram was: \n",
    "At least half a\n",
    "dozen more were severally drawn forth from the same box, and surveyed\n",
    "with equal pleasure; besides rings, brooches, bracelets, and other\n",
    "articles of jewellery, of such magnificent materials, and costly\n",
    "workmanship, that Oliver had no idea, even of their names.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lukeh\\Desktop\\Grad School\\MS_Data_Science_Drexel\\Data Prep\\Assignments\\Module C\\module-C\\module-C.ipynb Cell 55\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# C11:SanityCheck\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m (most_efficient_book, most_efficient_author, \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m  most_efficient_title, least_characters, best_pangram) \u001b[39m=\u001b[39m most_efficient_pangram(pangrams_by_book, books_metadata)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe best pangramming author, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m most_efficient_author \u001b[39m+\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m, wrote a \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(least_characters) \u001b[39m+\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m-character pangram in the book: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m most_efficient_title \u001b[39m+\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m (booknumber: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(most_efficient_book) \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mThis pangram was: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(best_pangram))\n",
      "\u001b[1;32mc:\\Users\\lukeh\\Desktop\\Grad School\\MS_Data_Science_Drexel\\Data Prep\\Assignments\\Module C\\module-C\\module-C.ipynb Cell 55\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         most_efficient_author \u001b[39m=\u001b[39m author\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         most_efficient_book \u001b[39m=\u001b[39m book_num\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         most_efficient_title \u001b[39m=\u001b[39m books_metadata[\u001b[39mint\u001b[39;49m(book_num)][\u001b[39m'\u001b[39m\u001b[39mTitle\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Convert book_num to int\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         best_pangram \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(pangrams, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lukeh/Desktop/Grad%20School/MS_Data_Science_Drexel/Data%20Prep/Assignments/Module%20C/module-C/module-C.ipynb#Y101sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (most_efficient_book, most_efficient_author, most_efficient_title, least_characters, best_pangram)\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# C11:SanityCheck\n",
    "\n",
    "(most_efficient_book, most_efficient_author, \n",
    " most_efficient_title, least_characters, best_pangram) = most_efficient_pangram(pangrams_by_book, books_metadata)\n",
    "\n",
    "\n",
    "print(\"The best pangramming author, \" + most_efficient_author +\n",
    "      \", wrote a \" + str(least_characters) +\n",
    "      \"-character pangram in the book: \\n\\\"\" + most_efficient_title +\n",
    "      \"\\\" (booknumber: \" + str(most_efficient_book) +\")\\n\\n\" +\n",
    "      \"This pangram was: \\n\" + \"\".join(best_pangram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
